# OpenAI API Configuration (optional — only required when EMBEDDING_PROVIDER=openai)
# If omitted, the server automatically falls back to free local embeddings.
OPENAI_API_KEY=sk-your-api-key-here

# Embedding Provider
# 'openai'  — uses OpenAI text-embedding-3-small/large (requires OPENAI_API_KEY)
# 'local'   — uses @huggingface/transformers locally (free, no API key needed)
# If not set, auto-detected: 'openai' when OPENAI_API_KEY is present, 'local' otherwise.
#EMBEDDING_PROVIDER=local

# Local embedding model (only used when EMBEDDING_PROVIDER=local)
# Default: Xenova/all-MiniLM-L6-v2 (384 dimensions, ~22 MB, fast)
# Alternatives:
#   Xenova/bge-small-en-v1.5   — 384 dims, slightly better quality
#   Xenova/bge-base-en-v1.5    — 768 dims, higher quality (~110 MB)
#LOCAL_EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2

# Output dimensions of the local model (must match the chosen model above)
#LOCAL_EMBEDDING_DIMENSIONS=384

# Directory to cache downloaded local models (default: ~/.cache/mcp-memory/models)
#LOCAL_EMBEDDING_CACHE_DIR=~/.cache/mcp-memory/models

# Qdrant Vector Database Configuration
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=mcp-memory
QDRANT_TIMEOUT=30000

# Server Configuration
LOG_LEVEL=info

# Memory Configuration
MEMORY_CHUNK_SIZE=1000
MEMORY_CHUNK_OVERLAP=200

# Large embedding dimensions (OpenAI provider only — text-embedding-3-large)
LARGE_EMBEDDING_DIMENSIONS=3072

# Workspace Configuration
WORKSPACE_AUTO_DETECT=true
WORKSPACE_DEFAULT=
WORKSPACE_CACHE_TTL=60000

# Rules Configuration
COPY_CLAUDE_RULES=true
